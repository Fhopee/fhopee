import pandas as pd
import requests
import os
import time
from urllib.parse import urljoin
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
# ä½ çš„ DedeCMS ä¸»è¡¨ (åŒ…å«å›¾ç‰‡è·¯å¾„)
ARCHIVES_CSV = "dede_archives.csv" 
# æ—§ç½‘ç«™åŸŸå
BASE_URL = "https://www.fhopepack.com"
# å›¾ç‰‡ä¿å­˜ä½ç½®
SAVE_DIR = "public/images/products"
# ===========================================

def download_image(url, save_path):
    """ä¸‹è½½å›¾ç‰‡ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        r = requests.get(url, headers=headers, timeout=15)
        if r.status_code == 200:
            with open(save_path, 'wb') as f:
                f.write(r.content)
            return True
        return False
    except Exception as e:
        # print(f"Error: {e}")
        return False

def main():
    print("ğŸš€ å¼€å§‹å›¾ç‰‡å¢é‡åŒæ­¥ (åªä¸‹è½½ç¼ºå¤±çš„)...")
    
    # 1. å‡†å¤‡ç›®å½•
    if not os.path.exists(SAVE_DIR):
        os.makedirs(SAVE_DIR)

    # 2. è¯»å– CSV
    try:
        df = pd.read_csv(ARCHIVES_CSV, encoding='utf-8')
    except:
        df = pd.read_csv(ARCHIVES_CSV, encoding='gb18030')

    # 3. ç­›é€‰æœ‰å›¾ç‰‡çš„è®°å½•
    # å‡è®¾å›¾ç‰‡åˆ—å« 'litpic'
    tasks = []
    for _, row in df.iterrows():
        img_path = str(row.get('litpic', ''))
        if img_path and img_path.lower() != 'nan' and img_path != '':
            tasks.append(img_path)

    print(f"ğŸ“Š æ€»å…±å‘ç° {len(tasks)} æ¡å›¾ç‰‡è®°å½•")

    downloaded_count = 0
    skipped_count = 0
    failed_count = 0

    # 4. éå†å¹¶æ£€æŸ¥
    for rel_path in tqdm(tasks, desc="Checking images"):
        # æ¸…æ´—è·¯å¾„
        if not rel_path.startswith('/'): rel_path = '/' + rel_path
        
        filename = os.path.basename(rel_path)
        # å»æ‰ URL å‚æ•° (?ver=1.0)
        filename = filename.split('?')[0] 
        
        local_path = os.path.join(SAVE_DIR, filename)
        
        # === æ ¸å¿ƒé€»è¾‘ï¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨ ===
        if os.path.exists(local_path) and os.path.getsize(local_path) > 0:
            skipped_count += 1
            continue  # è·³è¿‡ï¼Œä¸éœ€è¦ä¸‹è½½
        
        # === å¦‚æœä¸å­˜åœ¨ï¼Œæˆ–è€…æ–‡ä»¶å¤§å°ä¸º0ï¼Œåˆ™ä¸‹è½½ ===
        full_url = urljoin(BASE_URL, rel_path)
        success = download_image(full_url, local_path)
        
        if success:
            downloaded_count += 1
            time.sleep(0.1) #ç¨å¾®ä¼‘æ¯ä¸‹é˜²æ­¢å°IP
        else:
            failed_count += 1

    print("-" * 30)
    print(f"ğŸ‰ åŒæ­¥å®Œæˆï¼")
    print(f"â© å·²å­˜åœ¨(è·³è¿‡): {skipped_count}")
    print(f"âœ… æ–°å¢ä¸‹è½½: {downloaded_count}")
    print(f"âŒ ä¸‹è½½å¤±è´¥: {failed_count}")

if __name__ == "__main__":
    main()