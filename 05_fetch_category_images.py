import pandas as pd
import requests
import os
import json
import time
from urllib.parse import urljoin

# ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
ARCTYPE_CSV = "dede_arctype.csv" 
BASE_URL = "https://www.fhopepack.com"
IMAGE_SAVE_DIR = "public/images/categories"
OUTPUT_JSON = "data/categories_enriched.json"
# ==============================================

def download_image(img_path, save_dir):
    """ä¸‹è½½å›¾ç‰‡å¹¶è¿”å›æ–°çš„æœ¬åœ°è·¯å¾„"""
    # 1. åŸºç¡€æ¸…æ´—ï¼šå¦‚æœæ˜¯ç©ºå€¼æˆ–nan
    if not img_path or pd.isna(img_path) or str(img_path).lower() == 'nan':
        return None
    
    img_path = str(img_path).strip()
    if not img_path:
        return None
    
    # 2. è¡¥å…¨ç›¸å¯¹è·¯å¾„
    if not img_path.startswith('/'):
        img_path = '/' + img_path
        
    full_url = urljoin(BASE_URL, img_path)
    filename = os.path.basename(img_path)
    
    # 3. ç®€å•çš„æ–‡ä»¶åæ¸…æ´—ï¼ˆå»æ‰å¯èƒ½å¯¼è‡´æŠ¥é”™çš„å­—ç¬¦ï¼‰
    filename = filename.split('?')[0] # å»æ‰URLå‚æ•°
    
    local_path = os.path.join(save_dir, filename)
    public_path = f"/images/categories/{filename}" 

    # 4. å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
    if os.path.exists(local_path):
        # print(f"   â© å·²å­˜åœ¨ (è·³è¿‡): {filename}")
        return public_path

    # 5. ä¸‹è½½
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        r = requests.get(full_url, headers=headers, timeout=10)
        if r.status_code == 200:
            with open(local_path, 'wb') as f:
                f.write(r.content)
            print(f"   âœ… ä¸‹è½½æˆåŠŸ: {filename}")
            return public_path
        else:
            print(f"   âŒ ä¸‹è½½å¤±è´¥ ({r.status_code}): {full_url}")
            return None
    except Exception as e:
        print(f"   âŒ ä¸‹è½½é”™è¯¯: {e}")
        return None

def main():
    if not os.path.exists(ARCTYPE_CSV):
        print(f"æ‰¾ä¸åˆ° {ARCTYPE_CSV}ï¼Œè¯·ç¡®è®¤æ–‡ä»¶ä½ç½®ã€‚")
        return

    if not os.path.exists(IMAGE_SAVE_DIR):
        os.makedirs(IMAGE_SAVE_DIR)

    print("ğŸš€ å¼€å§‹å¤„ç† dede_arctype.csv ...")
    
    try:
        df = pd.read_csv(ARCTYPE_CSV, encoding='utf-8')
    except:
        df = pd.read_csv(ARCTYPE_CSV, encoding='gb18030') # å°è¯•GBKç¼–ç 

    categories = []

    for index, row in df.iterrows():
        # === å¼ºåˆ¶ç±»å‹è½¬æ¢ï¼Œé˜²æ­¢ AttributeError ===
        cat_id = str(row.get('id', '')).strip()
        typename = str(row.get('typename', '')).strip()
        parent_id = str(row.get('reid', '0')).strip()
        if parent_id == 'nan': parent_id = '0'
        
        # å¤„ç† Slug (è¿™é‡Œå°±æ˜¯ä½ æŠ¥é”™çš„åœ°æ–¹)
        raw_typedir = row.get('typedir', '')
        if pd.isna(raw_typedir):
            slug = ""
        else:
            # å¼ºåˆ¶è½¬å­—ç¬¦ä¸²å† replace
            slug = str(raw_typedir).replace('{cmspath}/', '').strip()

        # å¤„ç†å›¾ç‰‡
        raw_img = row.get('litpic', '') # ä¹Ÿå°±æ˜¯ç¼©ç•¥å›¾
        
        print(f"æ­£åœ¨å¤„ç† ID: {cat_id} - {typename}")

        local_img_url = download_image(raw_img, IMAGE_SAVE_DIR)

        cat_obj = {
            "id": cat_id,
            "name": typename,
            "parentId": parent_id,
            "slug": slug,
            "description": str(row.get('description', '')).replace('nan', ''),
            "image": local_img_url
        }
        categories.append(cat_obj)

    # ä¿å­˜ç»“æœ
    # ç¡®ä¿ data ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(OUTPUT_JSON), exist_ok=True)
    
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(categories, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ° {OUTPUT_JSON}")

if __name__ == "__main__":
    main()